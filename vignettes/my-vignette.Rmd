---
title: "multiarm: Design and analysis of fixed-sample multi-arm clinical trials"
author: "Michael J. Grayling, Newcastle University (michael.grayling@newcastle.ac.uk)"
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{multiarm: Design and analysis of fixed-sample multi-arm clinical trials}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = F}
knitr::opts_chunk$set(collapse = T,
                      comment  = "#>"
)
```

# 1. Introduction

__multiarm__ provides functionality to assist with the design and analysis of
fixed-sample multi-arm clinical trials utilising one of several supported
multiple comparison corrections. Available functions allow for sample size
determination (including for $A$-, $D$-, and $E$-optimal designs), trial
simulation, analytical operating characteristic calculation (including the
conjunctive power, disjunctive power, family-wise error-rate, and false
discovery rate), and the production of several plots. An R Shiny graphical user
interface is also provided to ease design determination.

This vignette will proceed by first precisely detailing the type of trial design
__multiarm__ supports. Each of the available functions will then be described,
before several examples and useful further information are provided.  

# 2. Fixed-sample multi-arm clinical trials

## 2.1. Design setting

__multiarm__ supports the design and analysis of fixed-sample multi-arm clinical
trials that use a many-to-one design. I.e., a design where a single shared
control treatment arm is compared in a pairwise manner to some number of
experimental treatment arms, following the accrual of outcome data from a
specified number of patients on each arm.

Formally, it supposes that outcomes $X_{ik}\sim N(\mu_k,\sigma_k^2)$ will be
accrued from patients $i\in\{1,\dots,n_k\}$ on treatment arms
$k\in\{0,\dots,K\}$. Then, specifying that arm $k=0$ corresponds to the shared
control arm, and arms $k\in\{1,\dots,K\}$ to the experimental arms, the
hypotheses of interest are assumed to be
$$ H_k\ :\ \tau_k = \mu_k - \mu_0 \le 0,\ \ k\in\{1,\dots,K\}.$$
That is, it tests whether the differences between the mean responses on arms
$k\in\{1,\dots,K\}$ and arm $k=0$ are negative, hoping that they will be
positive (i.e., we assume higher mean responses correspond to patient benefit).
Later, for brevity, we will make use of the notation
$\boldsymbol{\tau}=(\tau_1,\dots,\tau_K)^\top\in\mathbb{R}^K$.

To test hypothesis $H_k$, given outcomes $X_{ik}=x_{ik}$, we assume throughout
that a Wald-style test statistic, $z_k$, is computed

$$ z_k = \frac{\hat{\tau}_k}{\sqrt{\text{Var}(\hat{\tau}_k)}} = \hat{\tau}_kI_k^{1/2} =
\frac{\bar{x}_k - \bar{x}_0}{\sqrt{\frac{\sigma_0^2}{n_0} +
\frac{\sigma_k^2}{n_k}}},\ \ k\in\{1,\dots,K\}, $$
where
$$ \bar{x}_k = \frac{1}{n_k}\sum_{i=1}^{n_k}x_{ik},\ \ k\in\{0,\dots,K\}.$$
Thus, it is important to state here that __multiarm__ assumes that $\sigma_k^2$
is known for $k\in\{0,\dots,K\}$.

In what follows, we will use the notation
$\boldsymbol{z}_k=(z_1,\dots,z_k)^\top\in\mathbb{R}^k$. To this end, note that
$\boldsymbol{Z}_k$, the random (pre-trial) value of $\boldsymbol{z}_k$, has a
$k$-dimensional multivariate normal (MVN) distribution,
with

\begin{align}
\mathbb{E}(Z_l) &= \tau_lI_l^{1/2},\ l=1,\dots,k,\\
\text{Cov}(Z_{l_1},Z_{l_2}) &= I_{l_1}^{1/2}I_{l_2}^{1/2}\text{Cov}(\tau_{l_1},\tau_{l_2}) = I_{l_1}^{1/2}I_{l_2}^{1/2}\frac{\sigma_0^2}{n_0},\ l_1 \neq l_2,\ l_1,l_2\in\{1,\dots,k\},\\
I_l &= \frac{1}{\sqrt{\frac{\sigma_0^2}{n_0} +
\frac{\sigma_l^2}{n_l}}}, \ l=1,\dots,k.
\end{align}

Ultimately, $\boldsymbol{z}_K$ is converted to a vector of $p$-values,
$\boldsymbol{p}=(p_1,\dots,p_K)^\top\in[0,1]^K$, via
$$ p_k = 1 - \Phi_1(z_k,0,1),\ \ k\in\{1,\dots,K\}.$$
Here, $\Phi_n\{(a_1,\dots,a_n)^\top,\boldsymbol{\lambda},\Sigma\}$ is the
cumulative distribution function of an $n$-dimensional MVN distribution, with
mean $\boldsymbol{\lambda}$ and covariance matrix $\Sigma$. Precisely

$$ \Phi_n\{(a_1,\dots,a_n)^\top,\boldsymbol{\lambda},\Sigma\} = \int_{-\infty}^{a_1}\dots\int_{-\infty}^{a_n}\phi_n\{\boldsymbol{x},\boldsymbol{\lambda},\Sigma\}\mathrm{d}x_n\dots\mathrm{d}x_1, $$
where $\phi_n\{\boldsymbol{x},\boldsymbol{\lambda},\Sigma\}$ is the probability
density function of an $n$-dimensional MVN distribution with mean
$\boldsymbol{\lambda}$ and covariance matrix $\Sigma$, evaluated at vector
$\boldsymbol{x}=(x_1,\dots,x_n)^\top$.

Finally, to determine whether to reject each null hypothesis, the $p_k$ are
compared to a set of significance thresholds, which are specified based on a
chosen multiple comparison correction (see below), in combination with a
nominated significance level $\alpha\in(0,1)$.

With the above, the principal goal of __multiarm__ is to provide a set of
functions that

(a) helps choose the significance thresholds against which the $p_k$ are
compared, typically to control the family-wise error-rate (FWER, see Section
2.2);
(b) helps make choices on appropriate values for the $n_k$, $k\in\{0,\dots,K\}$,
to achieve some desired level of statistical power (see Section 2.3);
(c) helps evaluate the statistical characteristics of a chosen design.

The forthcoming sections now describe how exactly this is achieved.

## 2.2. Multiple comparison corrections

The most simple possible solution for selecting the significance thresholds
against which to compare the $p_k$, is to compare each to the chosen
significance level $\alpha$. I.e., to reject $H_k$ for $k\in\{1,\dots,K\}$ if
$p_k \le \alpha$. This controls the per-hypothesis
error-rate to $\alpha$.

The problem with this, however, particularly when $K$ is large, is that the
statistical operating characteristics of the resulting design may not be
desirable (e.g., in terms of the probability of incorrectly rejecting at least
one null hypothesis). For this reason, in general one may wish to make use of a
multiple comparison correction (MCC). Currently, __multiarm__ supports the use of
a variety of such MCCs, which aim to control either 

(a) the FWER, the probability of incorrectly rejecting at least one null
hypothesis
(with these techniques sub-divided into single-step, step-down, and step-up
procedures) or;
(b) the false discovery rate (FDR), the expected proportion of rejected null
hypotheses that are false.

### 2.2.1. Single-step family-wise error-rate control

These procedures test each of the $H_k$ against a common significance level,
$\pi$ say, rejecting $H_k$ if $p_k \le \pi$. The currently supported single-step
procedures are:

- __No MCC:__ Noted already above, this sets $\pi = \alpha$. It can be chosen
by setting `correction = "none"`.
- __Bonferroni's correction:__ This sets $\pi = \alpha/K$. It can be chosen by setting
`correction = "bonferroni"`.
- __Sidak's correction:__ This sets $\pi = 1 - (1 - \alpha)^{1/K}$. It can be
chosen by setting `correction = "sidak"`.
- __Dunnett's correction:__ This sets $\pi = 1 - \Phi_1\{z_D,0,1\}$, where
$z_\text{D}$ is the solution of the following equation
$$ \alpha = 1 - \Phi_K\{(z_D,\dots,z_D)^\top,\boldsymbol{0}_K,\text{Cov}(\boldsymbol{Z}_K)\}, $$
with $\boldsymbol{0}_n=(0,\dots,0)^\top\in\mathbb{R}^n$ an $n$-dimensional
vector of zeroes. It can be chosen by setting `correction = "dunnett"`.

Note that with the exception of the first method, "No MCC", all of the above
specify a $\pi$ such that the maximum probability of incorrectly rejecting
at least one of the null hypotheses $H_k$, $k\in\{1,\dots,K\}$, over all
possible values of $\boldsymbol{\tau}\in\mathbb{R}^K$ is at most $\alpha$. This
is referred to as *strong control* of the FWER.

### 2.2.2. Step-down family-wise error-rate control

These procedures work by first ranking the $p$-values from smallest to largest.
We will refer to these ranked $p$-values by $p_{(1)},\dots,p_{(K)}$, with
associated hypotheses $H_{(1)},\dots,H_{(K)}$. The $p_{(k)}$ are compared to a
vector of significance levels $\boldsymbol{\pi}=(\pi_1,\dots,\pi_K)\in(0,1)^K$.
Precisely, the maximal index $k$ such that $p_{(k)}>\pi_k$ is identified, and
then $H_{(1)},\dots,H_{(k-1)}$ are rejected and $H_{(k)},\dots,H_{(K)}$ are not
rejected. If $k=1$ then we do not reject any of the null hypotheses, and if no
such $k$ exists then we reject all of the null hypotheses. The currently
supported step-down procedures are

- __Holm's correction:__ This sets $\pi_k=\alpha/(K+1-k)$. It can be chosen by
setting `correction = "holm"`.
- __Step-down Dunnett correction:__ This can only currently be used when $\sigma_1^2/n_1=\dots=\sigma_K^2/n_K$. In this case, it sets
$\pi_k== 1 - \Phi\{z_{Dk}\}$, where $z_{Dk}$ is the solution to
$$ \alpha = 1 - \Phi_{K+1-k}\{(z_{Dk},\dots,z_{Dk})^\top,\boldsymbol{0}_{K+1-k},\text{Cov}(\boldsymbol{Z}_{K+1-k})\}. $$
It can be chosen by setting `correction = "step_down_dunnett"`.

Note that both of the above methods provide strong control of the FWER.

### 2.2.3. Step-up family-wise error-rate control

These procedures also work by first ranking the $p$-values from smallest to
largest, and utilise a vector of significance levels $\boldsymbol{\pi}$.
However, here, the largest $k$ such that $p_{(k)} \le \pi_k$ is identified.
Then, we reject the hypotheses $H_{(1)},\dots,H_{(k)}$, and do not reject $H_{(k+1)},\dots,H_{(K)}$. Currently, one such method is supported

- __Hochberg's correction:__ This sets $\pi_k=\alpha/(K+1-k)$. It can be chosen
by setting `correction = "hochberg"`.

This method also provides strong control of the FWER.

### 2.2.3. False discovery rate control

Whilst (most of) the above methods control the FWER in the strong sense, it may
be of interest instead to control the FDR. Currently, one method that will
control the FDR to at most $\alpha$ over all possible
$\boldsymbol{\tau}\in\mathbb{R}^K$ is supported:

- __Benjamini-Hochberg correction:__ Ascending $p$-values,
$p_{(1)},\dots,p_{(K)}$ are compared to $\pi_k=k\alpha/K$. The maximum $k$ for
which $p_{(k)}\le\pi_k$ is found, then $H_{(1)},\dots,H_{(k)}$ are rejected, and $H_{(k+1)},\dots,H_{(K)}$ are not.

## 2.3. Power and sample size determination

Powering a multi-arm trial is complex. Consequently, __multiarm__ supports
design determination for a variety of types of power, and will evaluate each of
the supported types of power by default.

In all, it requires values for
*interesting* and *uninteresting* treatment effects to be specified, $\delta_1\in\mathbb{R}^+$ and $\delta_0\in(-\infty,\delta_1)$ respectively.
With this, the following definitions are used:

- The *global null hypothesis*, $H_G$, is given by:
$$\tau_1=\cdots=\tau_K=0.$$
- The *global alternative hypothesis*, $H_A$, is given by:
$$\tau_1=\cdots=\tau_K=\delta_1.$$
- The *least favourable configuration* for experimental arm $k=1,\dots,K$,
$LFC_k$, is given by:
$$\tau_k=\delta_1,\ \tau_1=\cdots=\tau_{k-1}=\tau_{k+1}=\cdots=\tau_K=\delta_0.$$
For brevity, we will refer to the $\boldsymbol{\tau}$ implied by $LFC_k$ as
$\boldsymbol{\tau} = \boldsymbol{\theta}_k$.

And then, the following types of power can be calculated:

- __Conjunctive power:__ The probability all of the null hypotheses are
rejected:
$$P_\text{con}(\boldsymbol{\tau}) = \mathbb{P}(\text{Reject }H_k\text{ for }k\in\{1,\dots,K\} \mid \boldsymbol{\tau},\boldsymbol{\sigma},\boldsymbol{n}).$$
- __Disjunctive power:__ The probability at least one null hypothesis is
rejected:
$$P_\text{dis}(\boldsymbol{\tau}) = \mathbb{P}(\text{Reject }H_k\text{ for some }k\in\{1,\dots,K\} \mid \boldsymbol{\tau},\boldsymbol{\sigma},\boldsymbol{n}).$$
- __Marginal power__: The probability a particular null hypothesis is rejected: $$P_k(\boldsymbol{\tau}) = \mathbb{P}(\text{Reject }H_k \mid \boldsymbol{\tau},\boldsymbol{\sigma},\boldsymbol{n}).$$

In particular, the sample size required by a design to control each of these
types of power to a specified level $1-\beta$ (chosen using the argument `beta`)
under specific scenarios is then supported. That is, the option `power` can be
used to control each of the following types of power, in the following settings:

- __Conjunctive power under the global alternative hypothesis:__ Ensure that $P_\text{con}\{(\delta_1,\dots,\delta_1)^\top\} \ge 1 - \beta$. It can be chosen
by setting `power = "conjunctive"`.
- __Disjunctive power under the global alternative hypothesis:__ Ensure that $P_\text{dis}\{(\delta_1,\dots,\delta_1)^\top\} \ge 1 - \beta$.
It can be chosen by setting `power = "disjunctive"`.
- __Minimum marginal power under the least favourable configurations:__ Ensure
that $\min_{k\in\{1,\dots,K\}}P_k(\boldsymbol{\theta}_k) \ge 1 - \beta$. It can
be chosen by setting `power = "marginal"`.

## 2.5. Allocation ratios

All of the calculations discussed above are subject to the specification of
$\boldsymbol{n}=(n_0,\dots,n_K)$. Currently, __multiarm__ supports the
determination of values for $\boldsymbol{n}$ by identifying a suitable $n_0$,
and then setting $n_k=r_kn_k$ for $k\in\{1,\dots,K\}$, with $\boldsymbol{r}=(r_1,\dots,r_K)\in(0,\infty)^K$.

In turn, it allows $\boldsymbol{r}$ to be specified (via the argument `ratio`)
in a variety of ways. It can be specified explicitly as a numeric vector, or
alternatively can be determined in an optimal manner. Currently, __multiarm__
supports the determination of $\boldsymbol{r}$ for the following optimality
criteria:

- *A*-optimality: Minimize the trace of the inverse of the information matrix of
the design. It can be chosen by setting `ratio = "A"`.
- *D*-optimality: Maximize the determinant of the information matrix of the
design. It can be chosen by setting `ratio = "D"`.
- *E*-optimality: Maximize the minimum eigenvalue of the information matrix. It
can be chosen by setting `ratio = "E"`.

# 3. Functions

## 3.1. `des_ma()`

`des_ma()` is the primary function within __multiarm__. It is used to determine
fixed-sample multi-arm clinical trial designs attaining a desired level of a
specified type of power.

## 3.2. `des_int_ma()`

Whilst `des_ma()` supports the identification of optimised allocation ratios,
its methodology is flawed for this purpose in two ways. Firstly, by default it
treats the parameters $n_0,\dots,n_K$ as continuous variables, even though in
practice they must be integers. And secondly, it relies on asymptotic theory
that may not be reliable in small sample settings. `des_int_ma()` seeks to
address these limitations by searching for the truly optimal allocation of
a given number of patients across the treatment arms.

## 3.3. `build_ma()`

`des_ma()` and `des_int_ma()` search for a design based upon the chosen input
parameters. However, in certain circumstances there may be a specific design
that is of interest. `build_ma()` can be used to construct such a design,
specifically for subsequent use with the other commands available in
__multiarm__.

## 3.4. `plot.multiarm_des_ma()`

__multiarm__ can produce power plots curves for the outputs from `des_ma()`,
`des_int_ma()`, and `build_ma()`, via the S3 `plot.multiarm_des_ma()`.

## 3.5. `opchar_ma()`

Whilst `des_ma()`, `des_int_ma()`, and `build_ma()` return a small summary of
the statistical operating characteristics of a design, it may occassionally be
of interest to evaluate the operating characteristics of a design in a wider
range of settings. `opchar_ma()` is designed for this purpose.

## 3.6. `sim_ma()`

Each of the functions other than `sim_ma()` in __multiarm__ rely upon analytical
operating characteristic evaluation. However, in certain circumstances, most
likely when either (a) $K$ is large or (b) analytical evaluations need to be
validated, recourse to simulation is useful. `sim_ma()` is designed to be useful
in these settings.

## 3.7. `an_ma()`

The primary focus of __multiarm__ is currently to faciliate the design of
fixed-sample multi-arm clinical trials. However, given the complexity of some of
the supported MCCs, `an_ma()` is included to help analyse the results from a
trial as well.

## 3.8.`gui_ma()`

__multiarm__ is supported by an R shiny graphical user interface (GUI). This GUI
can be initialised with the command `gui_ma()`.

# 4. Examples

## 4.1. Example 1

We demonstrate the basic functionality provided in __multiarm__. First, identify
a design using `des_ma()` (with the default parameters):

```{r}
library(multiarm)
des <- des_ma(integer = T)
```

Note that the argument `integer` has been used because we will make a call to 
`sim_ma()` later on.

We can then plot power curves with `plot.multiarm_des_ma()` as follows:

```{r}
plot(des)
```

`des_ma()` contains a summary of the operating characteristics of the identified
design:

```{r}
des$opchar
```

We can validate these using `sim_ma()` with:

```{r}
sim_ma(des,
       tau = rbind(c(  0,   0),
                   c(0.5, 0.5),
                   c(0.5,   0),
                   c(  0, 0.5)))$sim
```

## 4.2. Example 2

Now, lets make use of some of the additional functionality from __multiarm__.

First, let's find a design for a scenario with $K=3$, using Holm's correction,
desiring to control the disjunctive power, choosing the allocation ratios
for $D$-optimality, in a scenario where the standard deviations differ across
the arms:

```{r}
des <- des_ma(K          = 3,
              sigma      = c(0.5, 1, 1.5, 2),
              ratio      = "D",
              correction = "holm",
              power      = "disjunctive",
              integer    = T)
```

Thus the total required sample size by the design is:

```{r}
des$N
```

And, the allocation ratios are:

```{r}
des$ratio
```

Now, lets compare this to the truly $D$-optimal allocation that can be
identified via `des_int_ma()`:

```{r}
des_int <- des_int_ma(K          = 3,
                      N          = 140,
                      sigma      = c(0.5, 1, 1.5, 2),
                      ratio      = "D",
                      correction = "holm",
                      power      = "disjunctive")
```

Here, the allocation ratios are:

```{r}
des_int$ratio
```

Thus, they are identical in this setting to those identified via `des_ma()`.

Next, note that the operating characeristics of the truly optimal design are:

```{r}
des_int$opchar
```

We can validate these with:

```{r}
sim_ma(des_int,
       tau = rbind(c(  0,   0,   0),
                   c(0.5, 0.5, 0.5),
                   c(0.5,   0,   0),
                   c(  0, 0.5,   0),
                   c(  0,   0, 0.5)))$sim
```

Or recreate them with `opchar_ma()` via:

```{r}
opchar_ma(des_int,
          tau = rbind(c(  0,   0,   0),
                      c(0.5, 0.5, 0.5),
                      c(0.5,   0,   0),
                      c(  0, 0.5,   0),
                      c(  0,   0, 0.5)))$opchar
```

Finally, let's analyse some $p$-values returned via this design:

```{r}
an_ma(des_int,
      pval = rbind(c( 0.01,  0.01,  0.01),
                   c( 0.02,  0.02,  0.02),
                   c( 0.01, 0.015,  0.02),
                   c(0.001,  0.03,  0.02),
                   c( 0.01,  0.06, 0.002)))$an
```

And, as earlier, we can produce power-curve plots with:

```{r}
plot(des_int)
```

# 5. Miscellaneous

## 5.1. Contact

The first-line response to a possible bug should be to submit it as a
*New issue* [here](https://github.com/mjg211/multiarm/issues). If the issue is
more complex, or a patch is not provided in reasonable time, please contact
Michael Grayling at michael.grayling@newcastle.ac.uk. Similarly, please feel
free to contact with suggestions for new features, or for further support with
using the package.

## 5.2. Citing multiarm

The latest details on how to cite __multiarm__ can be found using `citation()`:

```{r}
citation("multiarm")
```
